## Statistical language models
!!самое базовое введение!! [Jurafsky+Martin Chapter 3](https://web.stanford.edu/~jurafsky/slp3/3.pdf)

более подробно про сглаживание: [Michael Collins' NLP course slides](http://www.cs.columbia.edu/~mcollins/lm-spring2013.pdf)

[EM-алгоритм "в общих чертах"](https://habr.com/ru/post/501850/)

[G. Neubig. Neural machine translation and sequence-to-sequence models](https://arxiv.org/pdf/1703.01619.pdf) - разделы 3-4

[A. Karpathy. Neural Networks Zero to Hero](https://github.com/karpathy/nn-zero-to-hero) - лекция 2


## Neural language models
[G. Neubig. Neural machine translation and sequence-to-sequence models](https://arxiv.org/pdf/1703.01619.pdf) - разделы 5-6

[Karlsruhe Machine Translation course](https://www.coursera.org/lecture/machinetranslation/feed-foward-neural-network-language-model-2NSTS) - лекция про нейронные языковые модели с картинками

Ещё туториал с картинками: [часть 1 - forward pass](https://medium.com/@SauceCat/forward-propagation-for-feed-forward-networks-ac8fcb6bdd60), [часть 2 - backward pass](https://towardsdatascience.com/backward-propagation-for-feed-forward-networks-afdf9d038d21)

В NLP in action (см. материалы к 1 лекции) - Глава 5, **Baby steps with neural networks**

## Разное

(ещё можно посмотреть ссылки из основной литературы)

1. S. Chen and J. Goodman. An empirical study of smoothing techniques for language modeling.
Computer Speech and Language (1999) 13, 359–394.

2.  Kenneth Heafield. [Language Modeling](http://ufal.mff.cuni.cz/mtm15/files/09-language-modelling-kenneth-heafield.pdf)

3. [Kneser-Ney smoothing explained](http://www.foldl.me/2014/kneser-ney-smoothing/)

4. Yoav Goldberg. [The unreasonable effectiveness of Character-level Language Models.](https://nbviewer.jupyter.org/gist/yoavg/d76121dfde2618422139)
