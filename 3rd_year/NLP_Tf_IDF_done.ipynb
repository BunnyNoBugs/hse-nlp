{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По традиции начинаем с вопроса....\n",
    "\n",
    "У нас есть множество различных новостных статей на абсолютно разные темы. Нам нужно определить тему статьи (узкую) (найти в массе из 3000+ знаков какие-то самые значимые для этой статьи слова, которые делают её отличной от других статей и которые могут поступить в заголовок и составлять её  краткий пересказ) --- как нам это сделать? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидным образом, не все слова were created equal. Мы уже знакомы с рядос стоп слов, которые мы в лингвистике яростно выбрасываем из предложения, однако, и другие слова в тексте неравнознчны......."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF_IDF\n",
    "\n",
    "Что это? И зачем оно нужно? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По сути, это метрика, которая показывает насколько важно/релевантно слово в заданном документе. используется для анализа темы и в поисковиках.\n",
    "\n",
    "В этом семинаре мы попытаемся создать с помощью неё наш собственный поисковик."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представим, что нам на вход в поисковике поступило 'the brown cows'. У нас в мировой паутине лежит куча-куча-куча документов с множеством различных слов. Как по заданным словам понять, какой из них релевантнее? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пока забьём на морфологию для простоты "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # если нет pandas - не страшно - он тут для красоты\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inquery = 'the brown cows'\n",
    "\n",
    "documentA = 'the black man went out at night for a stroll past the brown cows he owned He also noticed a wolf on the stroll but did not pay attention ...'\n",
    "documentB = 'The brown children sat around the fire and sang the songs ...'\n",
    "documentC = 'Everything about brown cows.  Brown cows live in a harsh enviroment. The ... '\n",
    "documentD = 'Everything about cows. Cows live in different enviroments. The ...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы можем, не залезая в семантику, узнать, какой текст выдать первым?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf\n",
    "\n",
    "\n",
    "idf\n",
    "\n",
    "\n",
    "term frequency–inverse document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\avorl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "bagOfWordsA = nltk.word_tokenize(documentA.lower())\n",
    "bagOfWordsB = nltk.word_tokenize(documentB.lower())\n",
    "bagOfWordsC = nltk.word_tokenize(documentC.lower())\n",
    "bagOfWordsD = nltk.word_tokenize(documentD.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueWords = set(bagOfWordsA).union(set(bagOfWordsB)).union(set(bagOfWordsC)).union(set(bagOfWordsD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '...',\n",
       " 'a',\n",
       " 'about',\n",
       " 'also',\n",
       " 'and',\n",
       " 'around',\n",
       " 'at',\n",
       " 'attention',\n",
       " 'black',\n",
       " 'brown',\n",
       " 'but',\n",
       " 'children',\n",
       " 'cows',\n",
       " 'did',\n",
       " 'different',\n",
       " 'enviroment',\n",
       " 'enviroments',\n",
       " 'everything',\n",
       " 'fire',\n",
       " 'for',\n",
       " 'harsh',\n",
       " 'he',\n",
       " 'in',\n",
       " 'live',\n",
       " 'man',\n",
       " 'night',\n",
       " 'not',\n",
       " 'noticed',\n",
       " 'on',\n",
       " 'out',\n",
       " 'owned',\n",
       " 'past',\n",
       " 'pay',\n",
       " 'sang',\n",
       " 'sat',\n",
       " 'songs',\n",
       " 'stroll',\n",
       " 'the',\n",
       " 'went',\n",
       " 'wolf'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfWordsA = dict.fromkeys(uniqueWords, 0)\n",
    "for word in bagOfWordsA:\n",
    "    numOfWordsA[word] += 1\n",
    "\n",
    "numOfWordsB = dict.fromkeys(uniqueWords, 0)\n",
    "for word in bagOfWordsB:\n",
    "    numOfWordsB[word] += 1\n",
    "    \n",
    "numOfWordsC = dict.fromkeys(uniqueWords, 0)\n",
    "for word in bagOfWordsC:\n",
    "    numOfWordsC[word] += 1\n",
    "    \n",
    "numOfWordsD = dict.fromkeys(uniqueWords, 0)\n",
    "for word in bagOfWordsD:\n",
    "    numOfWordsD[word] += 1\n",
    "    \n",
    "df = pd.DataFrame([numOfWordsA, numOfWordsB,numOfWordsC, numOfWordsD ])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>owned</th>\n",
       "      <th>harsh</th>\n",
       "      <th>and</th>\n",
       "      <th>pay</th>\n",
       "      <th>everything</th>\n",
       "      <th>at</th>\n",
       "      <th>cows</th>\n",
       "      <th>he</th>\n",
       "      <th>also</th>\n",
       "      <th>out</th>\n",
       "      <th>around</th>\n",
       "      <th>songs</th>\n",
       "      <th>about</th>\n",
       "      <th>the</th>\n",
       "      <th>children</th>\n",
       "      <th>sat</th>\n",
       "      <th>black</th>\n",
       "      <th>noticed</th>\n",
       "      <th>stroll</th>\n",
       "      <th>did</th>\n",
       "      <th>went</th>\n",
       "      <th>...</th>\n",
       "      <th>attention</th>\n",
       "      <th>night</th>\n",
       "      <th>but</th>\n",
       "      <th>live</th>\n",
       "      <th>a</th>\n",
       "      <th>enviroments</th>\n",
       "      <th>past</th>\n",
       "      <th>.</th>\n",
       "      <th>for</th>\n",
       "      <th>fire</th>\n",
       "      <th>not</th>\n",
       "      <th>in</th>\n",
       "      <th>brown</th>\n",
       "      <th>man</th>\n",
       "      <th>on</th>\n",
       "      <th>enviroment</th>\n",
       "      <th>different</th>\n",
       "      <th>wolf</th>\n",
       "      <th>sang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   owned  harsh  and  pay  everything  at  cows  he  also  out  around  songs  \\\n",
       "0      1      0    0    1           0   1     1   2     1    1       0      0   \n",
       "1      0      0    1    0           0   0     0   0     0    0       1      1   \n",
       "2      0      1    0    0           1   0     2   0     0    0       0      0   \n",
       "3      0      0    0    0           1   0     2   0     0    0       0      0   \n",
       "\n",
       "   about  the  children  sat  black  noticed  stroll  did  went  ...  \\\n",
       "0      0    3         0    0      1        1       2    1     1    1   \n",
       "1      0    3         1    1      0        0       0    0     0    1   \n",
       "2      1    1         0    0      0        0       0    0     0    1   \n",
       "3      1    1         0    0      0        0       0    0     0    1   \n",
       "\n",
       "   attention  night  but  live  a  enviroments  past  .  for  fire  not  in  \\\n",
       "0          1      1    1     0  2            0     1  0    1     0    1   0   \n",
       "1          0      0    0     0  0            0     0  0    0     1    0   0   \n",
       "2          0      0    0     1  1            0     0  2    0     0    0   1   \n",
       "3          0      0    0     1  0            1     0  2    0     0    0   1   \n",
       "\n",
       "   brown  man  on  enviroment  different  wolf  sang  \n",
       "0      1    1   1           0          0     1     0  \n",
       "1      1    0   0           0          0     0     1  \n",
       "2      2    0   0           1          0     0     0  \n",
       "3      0    0   0           0          1     0     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему иногда всё же но стоит выкидывать стоп-слова - предлоги, артикли и союзы?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## давайте построим свой tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tf --- term frequency. В самом первом упрощении - это то, сколько раз слово встретилось в тексте (чем чаще искомое слово встретилось в заданном тексте по сравнению с другими, тем это слово релевантнее для текста (лучше отражает его тему) и рем этот текст релевантнее запросу), в чём тут проблема? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому есть всякие adjustments. Так часто tf слова в документе считается как количество раз, когда оно появилось в этом документе, деленное на общее число слов документе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, bagOfWords):\n",
    "    #напишите функцию, которая получает на ввход bagofwords и numOfWords, а возвращает словарь с tf-ами для каждого слова из numofwords\n",
    "    tfDict = {}\n",
    "    bagOfWordsCount = len(bagOfWords)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count / float(bagOfWordsCount)\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfA = computeTF(numOfWordsA, bagOfWordsA)\n",
    "tfB = computeTF(numOfWordsB, bagOfWordsB)\n",
    "tfC = computeTF(numOfWordsC, bagOfWordsC)\n",
    "tfD = computeTF(numOfWordsD, bagOfWordsD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'owned': 0.0,\n",
       " 'harsh': 0.0,\n",
       " 'and': 0.08333333333333333,\n",
       " 'pay': 0.0,\n",
       " 'everything': 0.0,\n",
       " 'at': 0.0,\n",
       " 'cows': 0.0,\n",
       " 'he': 0.0,\n",
       " 'also': 0.0,\n",
       " 'out': 0.0,\n",
       " 'around': 0.08333333333333333,\n",
       " 'songs': 0.08333333333333333,\n",
       " 'about': 0.0,\n",
       " 'the': 0.25,\n",
       " 'children': 0.08333333333333333,\n",
       " 'sat': 0.08333333333333333,\n",
       " 'black': 0.0,\n",
       " 'noticed': 0.0,\n",
       " 'stroll': 0.0,\n",
       " 'did': 0.0,\n",
       " 'went': 0.0,\n",
       " '...': 0.08333333333333333,\n",
       " 'attention': 0.0,\n",
       " 'night': 0.0,\n",
       " 'but': 0.0,\n",
       " 'live': 0.0,\n",
       " 'a': 0.0,\n",
       " 'enviroments': 0.0,\n",
       " 'past': 0.0,\n",
       " '.': 0.0,\n",
       " 'for': 0.0,\n",
       " 'fire': 0.08333333333333333,\n",
       " 'not': 0.0,\n",
       " 'in': 0.0,\n",
       " 'brown': 0.08333333333333333,\n",
       " 'man': 0.0,\n",
       " 'on': 0.0,\n",
       " 'enviroment': 0.0,\n",
       " 'different': 0.0,\n",
       " 'wolf': 0.0,\n",
       " 'sang': 0.08333333333333333}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idf --- The log of the number of documents divided by the number of documents that contain the word w. Inverse data frequency determines the weight of rare words across all documents in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def computeIDF(documents):\n",
    "    #для того, чтобы посчитать idf надо подать все документы в функцию сразу \n",
    "    #напишите функцию, считающую idf для каждого слова - на входе массив из numOfWords для всех текстов \n",
    "    #на выходе словарь для слов \n",
    "    #см. ввод и вывод ниже\n",
    "    N = len(documents)\n",
    "    \n",
    "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
    "    for document in documents: # \n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N / float(val))\n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = computeIDF([numOfWordsA, numOfWordsB, numOfWordsC, numOfWordsD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'owned': 1.3862943611198906,\n",
       " 'harsh': 1.3862943611198906,\n",
       " 'and': 1.3862943611198906,\n",
       " 'pay': 1.3862943611198906,\n",
       " 'everything': 0.6931471805599453,\n",
       " 'at': 1.3862943611198906,\n",
       " 'cows': 0.28768207245178085,\n",
       " 'he': 1.3862943611198906,\n",
       " 'also': 1.3862943611198906,\n",
       " 'out': 1.3862943611198906,\n",
       " 'around': 1.3862943611198906,\n",
       " 'songs': 1.3862943611198906,\n",
       " 'about': 0.6931471805599453,\n",
       " 'the': 0.0,\n",
       " 'children': 1.3862943611198906,\n",
       " 'sat': 1.3862943611198906,\n",
       " 'black': 1.3862943611198906,\n",
       " 'noticed': 1.3862943611198906,\n",
       " 'stroll': 1.3862943611198906,\n",
       " 'did': 1.3862943611198906,\n",
       " 'went': 1.3862943611198906,\n",
       " '...': 0.0,\n",
       " 'attention': 1.3862943611198906,\n",
       " 'night': 1.3862943611198906,\n",
       " 'but': 1.3862943611198906,\n",
       " 'live': 0.6931471805599453,\n",
       " 'a': 0.6931471805599453,\n",
       " 'enviroments': 1.3862943611198906,\n",
       " 'past': 1.3862943611198906,\n",
       " '.': 0.6931471805599453,\n",
       " 'for': 1.3862943611198906,\n",
       " 'fire': 1.3862943611198906,\n",
       " 'not': 1.3862943611198906,\n",
       " 'in': 0.6931471805599453,\n",
       " 'brown': 0.28768207245178085,\n",
       " 'man': 1.3862943611198906,\n",
       " 'on': 1.3862943611198906,\n",
       " 'enviroment': 1.3862943611198906,\n",
       " 'different': 1.3862943611198906,\n",
       " 'wolf': 1.3862943611198906,\n",
       " 'sang': 1.3862943611198906}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf_idf  целиком"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "тф_айдф для слова в документе - это просто произведение его тф в документе на его идф"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tfBagOfWords, idfs):\n",
    "    #давайте\n",
    "    tfidf = {}\n",
    "    for word, val in tfBagOfWords.items():\n",
    "        tfidf[word] = val * idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfA = computeTFIDF(tfA, idfs)\n",
    "tfidfB = computeTFIDF(tfB, idfs)\n",
    "tfidfC = computeTFIDF(tfC, idfs)\n",
    "tfidfD = computeTFIDF(tfD, idfs)\n",
    "df = pd.DataFrame([tfidfA, tfidfB, tfidfC, tfidfD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>owned</th>\n",
       "      <th>harsh</th>\n",
       "      <th>and</th>\n",
       "      <th>pay</th>\n",
       "      <th>everything</th>\n",
       "      <th>at</th>\n",
       "      <th>cows</th>\n",
       "      <th>he</th>\n",
       "      <th>also</th>\n",
       "      <th>out</th>\n",
       "      <th>around</th>\n",
       "      <th>songs</th>\n",
       "      <th>about</th>\n",
       "      <th>the</th>\n",
       "      <th>children</th>\n",
       "      <th>sat</th>\n",
       "      <th>black</th>\n",
       "      <th>noticed</th>\n",
       "      <th>stroll</th>\n",
       "      <th>did</th>\n",
       "      <th>went</th>\n",
       "      <th>...</th>\n",
       "      <th>attention</th>\n",
       "      <th>night</th>\n",
       "      <th>but</th>\n",
       "      <th>live</th>\n",
       "      <th>a</th>\n",
       "      <th>enviroments</th>\n",
       "      <th>past</th>\n",
       "      <th>.</th>\n",
       "      <th>for</th>\n",
       "      <th>fire</th>\n",
       "      <th>not</th>\n",
       "      <th>in</th>\n",
       "      <th>brown</th>\n",
       "      <th>man</th>\n",
       "      <th>on</th>\n",
       "      <th>enviroment</th>\n",
       "      <th>different</th>\n",
       "      <th>wolf</th>\n",
       "      <th>sang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.009589</td>\n",
       "      <td>0.09242</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.09242</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009589</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023974</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.115525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.09242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.046210</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.038358</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.046210</td>\n",
       "      <td>0.04621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.092420</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.046210</td>\n",
       "      <td>0.038358</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.09242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.057762</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.047947</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.057762</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.057762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     owned    harsh       and      pay  everything       at      cows  \\\n",
       "0  0.04621  0.00000  0.000000  0.04621    0.000000  0.04621  0.009589   \n",
       "1  0.00000  0.00000  0.115525  0.00000    0.000000  0.00000  0.000000   \n",
       "2  0.00000  0.09242  0.000000  0.00000    0.046210  0.00000  0.038358   \n",
       "3  0.00000  0.00000  0.000000  0.00000    0.057762  0.00000  0.047947   \n",
       "\n",
       "        he     also      out    around     songs     about  the  children  \\\n",
       "0  0.09242  0.04621  0.04621  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "1  0.00000  0.00000  0.00000  0.115525  0.115525  0.000000  0.0  0.115525   \n",
       "2  0.00000  0.00000  0.00000  0.000000  0.000000  0.046210  0.0  0.000000   \n",
       "3  0.00000  0.00000  0.00000  0.000000  0.000000  0.057762  0.0  0.000000   \n",
       "\n",
       "        sat    black  noticed   stroll      did     went  ...  attention  \\\n",
       "0  0.000000  0.04621  0.04621  0.09242  0.04621  0.04621  0.0    0.04621   \n",
       "1  0.115525  0.00000  0.00000  0.00000  0.00000  0.00000  0.0    0.00000   \n",
       "2  0.000000  0.00000  0.00000  0.00000  0.00000  0.00000  0.0    0.00000   \n",
       "3  0.000000  0.00000  0.00000  0.00000  0.00000  0.00000  0.0    0.00000   \n",
       "\n",
       "     night      but      live        a  enviroments     past         .  \\\n",
       "0  0.04621  0.04621  0.000000  0.04621     0.000000  0.04621  0.000000   \n",
       "1  0.00000  0.00000  0.000000  0.00000     0.000000  0.00000  0.000000   \n",
       "2  0.00000  0.00000  0.046210  0.04621     0.000000  0.00000  0.092420   \n",
       "3  0.00000  0.00000  0.057762  0.00000     0.115525  0.00000  0.115525   \n",
       "\n",
       "       for      fire      not        in     brown      man       on  \\\n",
       "0  0.04621  0.000000  0.04621  0.000000  0.009589  0.04621  0.04621   \n",
       "1  0.00000  0.115525  0.00000  0.000000  0.023974  0.00000  0.00000   \n",
       "2  0.00000  0.000000  0.00000  0.046210  0.038358  0.00000  0.00000   \n",
       "3  0.00000  0.000000  0.00000  0.057762  0.000000  0.00000  0.00000   \n",
       "\n",
       "   enviroment  different     wolf      sang  \n",
       "0     0.00000   0.000000  0.04621  0.000000  \n",
       "1     0.00000   0.000000  0.00000  0.115525  \n",
       "2     0.09242   0.000000  0.00000  0.000000  \n",
       "3     0.00000   0.115525  0.00000  0.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "посмотрим на brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Автоматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform([documentA, documentB, documentC, documentD])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>also</th>\n",
       "      <th>and</th>\n",
       "      <th>around</th>\n",
       "      <th>at</th>\n",
       "      <th>attention</th>\n",
       "      <th>black</th>\n",
       "      <th>brown</th>\n",
       "      <th>but</th>\n",
       "      <th>children</th>\n",
       "      <th>cows</th>\n",
       "      <th>did</th>\n",
       "      <th>different</th>\n",
       "      <th>enviroment</th>\n",
       "      <th>enviroments</th>\n",
       "      <th>everything</th>\n",
       "      <th>fire</th>\n",
       "      <th>for</th>\n",
       "      <th>harsh</th>\n",
       "      <th>he</th>\n",
       "      <th>in</th>\n",
       "      <th>live</th>\n",
       "      <th>man</th>\n",
       "      <th>night</th>\n",
       "      <th>not</th>\n",
       "      <th>noticed</th>\n",
       "      <th>on</th>\n",
       "      <th>out</th>\n",
       "      <th>owned</th>\n",
       "      <th>past</th>\n",
       "      <th>pay</th>\n",
       "      <th>sang</th>\n",
       "      <th>sat</th>\n",
       "      <th>songs</th>\n",
       "      <th>stroll</th>\n",
       "      <th>the</th>\n",
       "      <th>went</th>\n",
       "      <th>wolf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.184851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.184851</td>\n",
       "      <td>0.184851</td>\n",
       "      <td>0.184851</td>\n",
       "      <td>0.117988</td>\n",
       "      <td>0.184851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117988</td>\n",
       "      <td>0.184851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.184851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.369701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.184851</td>\n",
       "      <td>0.184851</td>\n",
       "      <td>0.184851</td>\n",
       "      <td>0.184851</td>\n",
       "      <td>0.184851</td>\n",
       "      <td>0.184851</td>\n",
       "      <td>0.184851</td>\n",
       "      <td>0.184851</td>\n",
       "      <td>0.184851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.369701</td>\n",
       "      <td>0.289388</td>\n",
       "      <td>0.184851</td>\n",
       "      <td>0.184851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.318493</td>\n",
       "      <td>0.318493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.203290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.318493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.318493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.318493</td>\n",
       "      <td>0.318493</td>\n",
       "      <td>0.318493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.498608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.278433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.450831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.450831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.278433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.278433</td>\n",
       "      <td>0.278433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.184292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.311932</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.505071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.395646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.395646</td>\n",
       "      <td>0.311932</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.311932</td>\n",
       "      <td>0.311932</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.206464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      about      also       and    around        at  attention     black  \\\n",
       "0  0.000000  0.184851  0.000000  0.000000  0.184851   0.184851  0.184851   \n",
       "1  0.000000  0.000000  0.318493  0.318493  0.000000   0.000000  0.000000   \n",
       "2  0.278433  0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "3  0.311932  0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "\n",
       "      brown       but  children      cows       did  different  enviroment  \\\n",
       "0  0.117988  0.184851  0.000000  0.117988  0.184851   0.000000    0.000000   \n",
       "1  0.203290  0.000000  0.318493  0.000000  0.000000   0.000000    0.000000   \n",
       "2  0.450831  0.000000  0.000000  0.450831  0.000000   0.000000    0.353157   \n",
       "3  0.000000  0.000000  0.000000  0.505071  0.000000   0.395646    0.000000   \n",
       "\n",
       "   enviroments  everything      fire       for     harsh        he        in  \\\n",
       "0     0.000000    0.000000  0.000000  0.184851  0.000000  0.369701  0.000000   \n",
       "1     0.000000    0.000000  0.318493  0.000000  0.000000  0.000000  0.000000   \n",
       "2     0.000000    0.278433  0.000000  0.000000  0.353157  0.000000  0.278433   \n",
       "3     0.395646    0.311932  0.000000  0.000000  0.000000  0.000000  0.311932   \n",
       "\n",
       "       live       man     night       not   noticed        on       out  \\\n",
       "0  0.000000  0.184851  0.184851  0.184851  0.184851  0.184851  0.184851   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.278433  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.311932  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      owned      past       pay      sang       sat     songs    stroll  \\\n",
       "0  0.184851  0.184851  0.184851  0.000000  0.000000  0.000000  0.369701   \n",
       "1  0.000000  0.000000  0.000000  0.318493  0.318493  0.318493  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        the      went      wolf  \n",
       "0  0.289388  0.184851  0.184851  \n",
       "1  0.498608  0.000000  0.000000  \n",
       "2  0.184292  0.000000  0.000000  \n",
       "3  0.206464  0.000000  0.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь даваайте создадим наш парсер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pymorphy2\n",
    "import string\n",
    "import re\n",
    "from math import log\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "vectorizer1 = CountVectorizer(binary = True)\n",
    "vectorizertf = TfidfVectorizer(use_idf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quora\n",
    "\n",
    "['', 'question1', 'question2', 'is_duplicate']\n",
    "\n",
    "['0', 'Какова история кохинор кох-и-ноор-бриллиант', 'что произойдет, если правительство Индии украдет кохинор кох-и-ноор-алмаз назад', '0']\n",
    "\n",
    "['1', 'как я могу увеличить скорость моего интернет-соединения, используя vpn', 'как повысить скорость интернета путем взлома через dns', '0']\n",
    "\n",
    "['2', 'почему я мысленно очень одинок, как я могу это решить', 'найти остаток, когда математика 23 ^ 24 математика разделена на 24 23', '0']\n",
    "\n",
    "['3', 'которые растворяют в воде быстро сахарную соль метан и углеродный диоксид', 'какая рыба выживет в соленой воде', '0']\n",
    "\n",
    "['4', 'астрология: я - луна-колпачок из козерога и крышка, поднимающая то, что это говорит обо мне', 'Я тройная луна-козерог и восхождение в козероге, что это говорит обо мне', '1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "давайте обработаем только  20 000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts(): # возвращаем [corpus, inquiery, scores, normal]\n",
    "    corpus = [] #сюда кладём тексты из [2] столбца, где каждое слово прошло препроцессинг\n",
    "                #(нижний регистр, нет знаков препинания) и каждое слово в начальной форме\n",
    "    inquiery = [] #сюда кладём тексты из [1] столбца - их препроцесить не надо\n",
    "    #lenghths = []\n",
    "    scores = [] #сюда кладём информацию из [3] -- является ли ответ соответсвующим вопросу\n",
    "    normal = [] #сюда кладём тексты из [2] столбца - непрепроцесенные\n",
    "\n",
    "    with open('quora_question_pairs_rus.csv', encoding = 'utf-8') as csvfile:\n",
    "        readCSV = csv.reader(csvfile, delimiter=',')\n",
    "        for row in readCSV:\n",
    "            # отсюда убрать\n",
    "            normal.append(row[2])\n",
    "            text = preproc(row[2])\n",
    "            corpus.append(text)\n",
    "            inquiery.append(row[1])\n",
    "            #lenghths.append(len(text.split(' ')))\n",
    "            scores.append(row[3])\n",
    "            if len(scores) == 20000: #оч плохо\n",
    "                #return [corpus, inquiery, lenghths, scores, normal]\n",
    "                return [corpus, inquiery, scores, normal]\n",
    "\n",
    "def preproc(data):                      # препроцессинг (убираем знаки препинания и числа, приводим всё к начальной форме)\n",
    "            data = data.split()        \n",
    "            text = ''                   # числа есть только в тех информации, в самом скрипте все числа пишутся буквами\n",
    "            for word in data:\n",
    "                word = word.strip('[!,.?\"]')\n",
    "                p = morph.parse(word.strip())[0]\n",
    "                p = p.normal_form\n",
    "                if p != '-':\n",
    "                    if re.search(r'\\d', p) == None:\n",
    "                        text  = text + ' ' + p\n",
    "            return text[1:]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_texts, inquiery_texts, scores, normal_texts =  data[0][1:], data[1][1:], data[2][1:], data[3][1:]\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['что произойти если правительство индия украсть кохинор кох-и-ноор-алмаз назад', 'как повысить скорость интернет путём взлом через dns', 'найти остаток когда математик ^ математик разделить на', 'какой рыба выжить в солёный вода', 'я тройной луна-козерог и восхождение в козерог что это говорить о я']\n",
      "['Какова история кохинор кох-и-ноор-бриллиант', 'как я могу увеличить скорость моего интернет-соединения, используя vpn', 'почему я мысленно очень одинок, как я могу это решить', 'которые растворяют в воде быстро сахарную соль метан и углеродный диоксид', 'астрология: я - луна-колпачок из козерога и крышка, поднимающая то, что это говорит обо мне']\n",
      "['0', '0', '0', '0', '1']\n"
     ]
    }
   ],
   "source": [
    "print(corpus_texts[:5])\n",
    "print(inquiery_texts[:5])\n",
    "print(scores[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_matrix1 = vectorizer1.fit_transform(corpus_texts)\n",
    "voc = vectorizer1.get_feature_names() #получили вокабуляр -- какие вообще есть слова, у каждого еще и свой индекс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airtel',\n",
       " 'aiyoo',\n",
       " 'ajax',\n",
       " 'ajay',\n",
       " 'aka',\n",
       " 'akamai',\n",
       " 'akc',\n",
       " 'al',\n",
       " 'alabama',\n",
       " 'alan',\n",
       " 'alanganallur',\n",
       " 'albany',\n",
       " 'alchemyapi',\n",
       " 'alchievers',\n",
       " 'alephti',\n",
       " 'aleppo',\n",
       " 'alex',\n",
       " 'alexa',\n",
       " 'ali',\n",
       " 'alia',\n",
       " 'alibaba',\n",
       " 'aliexpress',\n",
       " 'allahabad',\n",
       " 'allbestlist',\n",
       " 'allen',\n",
       " 'allo',\n",
       " 'almos',\n",
       " 'alpha',\n",
       " 'als',\n",
       " 'am']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc [70:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "вообще для этих целей лучше использовать словарь, но..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = vectorizertf.fit_transform(corpus_texts)\n",
    "tf = tf.toarray() # это матрица!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_mat( inquiery, voc):\n",
    "    #делаем препроцессинг инквери\n",
    "    inq = preproc(inquiery)\n",
    "    # создали вектор из нулей, равный нашему вакабуляру по длине\n",
    "    vec = np.zeros((len(voc)))\n",
    "    for word in inq.split(' '):\n",
    "        if word in voc:\n",
    "            index = voc.index(word)\n",
    "            vec[index] = 1 # нули начинают заполняться единицами\n",
    "    res = np.dot(tf,vec) #перемножили вектора и матрицы --- получили что? -- \n",
    "    # https://zaochnik.com/spravochnik/matematika/matritsy/umnozhenie-matrits/\n",
    "    #по сути, те ребята, у которых не было ни одного слова совпадающего с запросом сразу редуцировались в ноль\n",
    "    # а у тех, у кого было мы с помощью такого умножения определили им , ктот релевантнее через тф_идф, получив числа\n",
    "    \n",
    "    results = np.argsort(res)[::-1][:5]\n",
    "    \n",
    "   \n",
    "    for i in results:\n",
    "        print(normal_texts[i])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "как работает правительство Индии\n",
      "почему правительство Индии запрещает все\n",
      "какая разница между парламентом и правительством Индии\n",
      "есть ли квота в Индии в Индии?\n",
      "каковы преимущества решения правительства Индии о вывозе 500 и 1000 рупий\n"
     ]
    }
   ],
   "source": [
    "search_mat('правительство индии',voc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Много переменных +,если это не quora, персонализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
