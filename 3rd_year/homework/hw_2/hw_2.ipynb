{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Русский текст\n",
    "\n",
    "Вчера был очень необычный день. Сначала я услышал странный разговор. Один говорил другому: «Это невозможно! Эти типы стали есть на складе! Мало того, что после них образовалась течь, так мне потом пришлось и печь чистить!». Этот разговор я слышал, пока шел дорогой домой: видимо, они работают на заводе (у одного из них была в руках пила). Потом, когда я проходил мимо парка, я увидел, что от него остались только пни, а вокруг них жгут траву. Видимо, это они спугнули целый рой пчел, и он полетел за мной. Было страшно, как будто бы к виску приставили дуло пистолета. В общем, день был такой неординарный, что я даже решил стих о нем сочинить.\n",
    "\n",
    "В тексте присутствуют неоднозначные формы: \"стали\", \"течь\", \"печь\", \"дорогой\", \"пила\", \"пни\", \"жгут\", \"рой\", \"дуло\", \"стих\" и другие.\n",
    "\n",
    "### Английский текст\n",
    "\n",
    "Yesterday was a really bad day. Firstly, I overheard a strange talk. One person was speaking to the other: “That is unbearable! There was a fellow who started eating at the warehouse! Not only I had to fix a leak after them, but I also had to clean the stove!”. I heard this conversation while I was on my way home. It seemed like both of them work at the factory (one of them had a saw in his hands). Later, when I was going past the park, I saw that only stumps were left of it and they were burning the grass around them. Apparently, they have scared off a swarm of bees and it started chasing me. I was so scared as if someone was threatening me with a gun. All in all, the day was so unusual that I have decided to write a few rhymes about it.\n",
    "\n",
    "Для английского текста даже не нужно было подбирать неоднозначные слова: они сами собой появились в переводе русского текста. По большей части это омонимия глагола и существительного-результата: \"talk\", \"fix\", \"leak\", \"gun\" и другие. Присутствуют также другие типы омонимий: прилагательное/существительное (\"fellow\"), несвязанные по смыслу существительное и форма глагола (\"saw\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я решил добавить еще один тэггер для русского -- rnnmorph. Он создан на основе pymorphy2, и его преимущество в том, что он учитывает контекст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-22 01:20:46,000 loading file C:\\Users\\User\\.flair\\models\\en-pos-ontonotes-v0.4.pt\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "m = Mystem()\n",
    "\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()\n",
    "\n",
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    \n",
    "    PER,\n",
    "    NamesExtractor,\n",
    "\n",
    "    Doc\n",
    ")\n",
    "segmenter = Segmenter()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "\n",
    "from rnnmorph.predictor import RNNMorphPredictor\n",
    "predictor = RNNMorphPredictor(language=\"ru\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(r\"C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\en_core_web_sm\\en_core_web_sm-2.3.1\")\n",
    "\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "tagger = SequenceTagger.load('upos')\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Русский язык"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_paths = glob.glob('*.txt')\n",
    "\n",
    "for i in text_paths:\n",
    "    with open(i, encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        text = [w for w in word_tokenize(text) if w.isalpha()]\n",
    "        df = pd.DataFrame(text, columns={'token'})\n",
    "        df.to_csv(i.replace('txt', 'csv'), sep='\\t')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_df = pd.read_csv('russian.csv', sep='\\t', index_col=0)\n",
    "english_df = pd.read_csv('english.csv', sep='\\t', index_col=0)\n",
    "\n",
    "with open('russian.txt', encoding='utf-8') as f:\n",
    "    russian = f.read()\n",
    "with open('english.txt', encoding='utf-8') as f:\n",
    "    english = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_df.to_csv('russian.csv', sep='\\t')\n",
    "english_df.to_csv('english.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymorphy_pred = []\n",
    "\n",
    "for i in russian_df['token']:\n",
    "    ana = morph.parse(i)[0]\n",
    "    pymorphy_pred.append(ana.tag.POS)\n",
    "    \n",
    "russian_df['pymorphy_pred'] = pd.Series(pymorphy_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem_pred = []\n",
    "\n",
    "ana = m.analyze(russian)\n",
    "for word in ana:\n",
    "    if 'analysis' in word:\n",
    "        gr = word['analysis'][0]['gr']\n",
    "        pos = gr.split('=')[0].split(',')[0]\n",
    "        mystem_pred.append(pos)\n",
    "\n",
    "russian_df['mystem_pred'] = pd.Series(mystem_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = Doc(russian)\n",
    "doc.segment(segmenter)\n",
    "doc.tag_morph(morph_tagger)\n",
    "\n",
    "natasha_pred = []\n",
    "\n",
    "for i in doc.sents:\n",
    "    for j in i.morph.tokens:\n",
    "        if j.pos != 'PUNCT':\n",
    "            natasha_pred.append(j.pos)\n",
    "\n",
    "russian_df['natasha_pred'] = pd.Series(natasha_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "forms = predictor.predict(list(russian_df['token']))\n",
    "rnnmorph_pred = [ana.pos for ana in forms]\n",
    "\n",
    "russian_df['rnnmorph_pred'] = pd.Series(rnnmorph_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_russian_tag(tag):\n",
    "    if tag in [\n",
    "        'ADVB',\n",
    "        'ADV',\n",
    "        'ADVPRO'\n",
    "    ]:\n",
    "        standard_tag = 'ADV'\n",
    "    elif tag in [\n",
    "        'VERB',\n",
    "        'V',\n",
    "        'AUX'\n",
    "    ]:\n",
    "        standard_tag = 'V'\n",
    "    elif tag in [\n",
    "        'ADJ',\n",
    "        'ADJF',\n",
    "        'A',\n",
    "        'ADJS'\n",
    "    ]:\n",
    "        standard_tag = 'ADJ'\n",
    "    elif tag in [\n",
    "        'N',\n",
    "        'NOUN',\n",
    "        'S',\n",
    "        'PROPN'\n",
    "    ]:\n",
    "        standard_tag = 'N'\n",
    "    elif tag in [\n",
    "        'PRO',\n",
    "        'NPRO',\n",
    "        'SPRO',\n",
    "        'PRON',\n",
    "        'APRO',\n",
    "        'DET'\n",
    "    ]:\n",
    "        standard_tag = 'PRO'\n",
    "    elif tag in [\n",
    "        'NUM'\n",
    "    ]:\n",
    "        standard_tag = 'NUM'\n",
    "    elif tag in [\n",
    "        'CONJ',\n",
    "        'SCONJ',\n",
    "        'CCONJ'\n",
    "    ]:\n",
    "        standard_tag = 'CONJ'\n",
    "    elif tag in [\n",
    "        'VERB',\n",
    "        'V',\n",
    "        'INFN'\n",
    "    ]:\n",
    "        standard_tag = 'V'\n",
    "    elif tag in [\n",
    "        'PRCL',\n",
    "        'PART'\n",
    "    ]:\n",
    "        standard_tag = 'PRCL'\n",
    "    elif tag in [\n",
    "        'INTJ'\n",
    "    ]:\n",
    "        standard_tag = 'INTJ'\n",
    "    elif tag in [\n",
    "        'PREP',\n",
    "        'PR',\n",
    "        'ADP'\n",
    "    ]:\n",
    "        standard_tag = 'PREP'\n",
    "        \n",
    "    return standard_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in russian_df.drop(['token', 'golden_pos'], axis=1).iterrows():\n",
    "    for n in j:\n",
    "        converted_tag = convert_russian_tag(n)\n",
    "        if converted_tag == 'Error':\n",
    "            print(converted_tag, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['pymorphy_pred', 'mystem_pred', 'natasha_pred', 'rnnmorph_pred']:\n",
    "    russian_df[i] = russian_df[i].apply(convert_russian_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>golden_pos</th>\n",
       "      <th>pymorphy_pred</th>\n",
       "      <th>mystem_pred</th>\n",
       "      <th>natasha_pred</th>\n",
       "      <th>rnnmorph_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Вчера</td>\n",
       "      <td>ADV</td>\n",
       "      <td>ADV</td>\n",
       "      <td>ADV</td>\n",
       "      <td>ADV</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>был</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>очень</td>\n",
       "      <td>ADV</td>\n",
       "      <td>ADV</td>\n",
       "      <td>ADV</td>\n",
       "      <td>ADV</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>необычный</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>день</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>решил</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>стих</td>\n",
       "      <td>N</td>\n",
       "      <td>V</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>о</td>\n",
       "      <td>PREP</td>\n",
       "      <td>PREP</td>\n",
       "      <td>PREP</td>\n",
       "      <td>PREP</td>\n",
       "      <td>PREP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>нем</td>\n",
       "      <td>PRO</td>\n",
       "      <td>A</td>\n",
       "      <td>PRO</td>\n",
       "      <td>PRO</td>\n",
       "      <td>PRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>сочинить</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         token golden_pos pymorphy_pred mystem_pred natasha_pred rnnmorph_pred\n",
       "0        Вчера        ADV           ADV         ADV          ADV           ADV\n",
       "1          был          V             V           V            V             V\n",
       "2        очень        ADV           ADV         ADV          ADV           ADV\n",
       "3    необычный        ADJ             A           A            A             A\n",
       "4         день          N             N           N            N             N\n",
       "..         ...        ...           ...         ...          ...           ...\n",
       "106      решил          V             V           V            V             V\n",
       "107       стих          N             V           N            N             N\n",
       "108          о       PREP          PREP        PREP         PREP          PREP\n",
       "109        нем        PRO             A         PRO          PRO           PRO\n",
       "110   сочинить          V             V           V            V             V\n",
       "\n",
       "[111 rows x 6 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "russian_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores for russian:\n",
      "\n",
      "pymorphy: 0.8108108108108109\n",
      "mystem: 0.9009009009009009\n",
      "natasha: 0.8738738738738738\n",
      "rnnmorph: 0.8828828828828829\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy scores for russian:')\n",
    "print('')\n",
    "for i in ['pymorphy', 'mystem', 'natasha', 'rnnmorph']:\n",
    "    accuracy = accuracy_score(russian_df['golden_pos'], russian_df[i + '_pred'])\n",
    "    print(f'{i}: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Английский язык"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in c:\\program files\\python37\\lib\\site-packages (from en_core_web_sm==2.3.1) (2.3.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\program files\\python37\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.50.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\program files\\python37\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\program files\\python37\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\program files\\python37\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.22.0)\n",
      "Requirement already satisfied: thinc==7.4.1 in c:\\program files\\python37\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\program files\\python37\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\program files\\python37\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\program files\\python37\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\python37\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (50.3.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\program files\\python37\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\program files\\python37\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\program files\\python37\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.17.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\program files\\python37\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\program files\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\program files\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.25.6)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\program files\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\program files\\python37\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.23)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\program files\\python37\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in c:\\program files\\python37\\lib\\site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.2.0)\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\universal_tagset.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_pred = [ana[1]for ana in nltk.pos_tag(english_df['token'], tagset='universal')]\n",
    "\n",
    "english_df['nltk_pred'] = pd.Series(nltk_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_doc = nlp(english)\n",
    "spacy_pred = [token.pos_ for token in spacy_doc if token.pos_ != 'PUNCT']\n",
    "english_df['spacy_pred'] = pd.Series(spacy_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_english_tag(tag):\n",
    "    if tag in [\n",
    "        'CCONJ',\n",
    "        'CONJ'\n",
    "    ]:\n",
    "        converted_tag = 'CONJ'\n",
    "    if tag in [\n",
    "        'PART',\n",
    "        'PRT'\n",
    "    ]:\n",
    "        converted_tag = 'PRT'\n",
    "    else:\n",
    "        converted_tag = tag\n",
    "    \n",
    "    return converted_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_df['spacy_pred'] = english_df['spacy_pred'].apply(convert_english_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_sentences = sent_tokenize(english)\n",
    "flair_pred = []\n",
    "for i in english_sentences:\n",
    "    sentence = Sentence(i)\n",
    "    tagger.predict(sentence)\n",
    "    flair_ana = sentence.to_tagged_string()\n",
    "    flair_ana = [t for t in re.findall(r'<(.+?)>', flair_ana)]\n",
    "    flair_ana = [t for t in flair_ana if t != 'PUNCT']\n",
    "    flair_pred.extend(flair_ana)\n",
    "    \n",
    "flair_pred = [convert_english_tag(t) for t in flair_pred]\n",
    "english_df['flair_pred'] = pd.Series(flair_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>golden_pos</th>\n",
       "      <th>nltk_pred</th>\n",
       "      <th>spacy_pred</th>\n",
       "      <th>flair_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Yesterday</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>was</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DET</td>\n",
       "      <td>DET</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>really</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADV</td>\n",
       "      <td>ADV</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>bad</td>\n",
       "      <td>ADV</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DET</td>\n",
       "      <td>DET</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>few</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>rhymes</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>about</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>it</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         token golden_pos nltk_pred spacy_pred flair_pred\n",
       "0    Yesterday       NOUN      NOUN       NOUN       NOUN\n",
       "1          was       VERB      VERB       VERB       VERB\n",
       "2            a        DET       DET        DET        DET\n",
       "3       really        ADJ       ADV        ADV        ADV\n",
       "4          bad        ADV       ADJ        ADJ        ADJ\n",
       "..         ...        ...       ...        ...        ...\n",
       "146          a        DET       DET        DET        DET\n",
       "147        few        ADJ       ADJ        ADJ        ADJ\n",
       "148     rhymes       NOUN      NOUN       NOUN       NOUN\n",
       "149      about        ADP       ADP        ADP        ADP\n",
       "150         it       PRON      PRON       PRON       PRON\n",
       "\n",
       "[151 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores for english:\n",
      "\n",
      "nltk: 0.8741721854304636\n",
      "spacy: 0.8609271523178808\n",
      "flair: 0.8741721854304636\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy scores for english:')\n",
    "print('')\n",
    "for i in ['nltk', 'spacy', 'flair']:\n",
    "    accuracy = accuracy_score(english_df['golden_pos'], english_df[i + '_pred'])\n",
    "    print(f'{i}: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
