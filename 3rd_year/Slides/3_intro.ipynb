{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9738c832",
   "metadata": {},
   "source": [
    "# Токенизация\n",
    "\n",
    "Как разделить текст на предложения?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9332edeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr', ' Smith bought ticket to San Francisco', ' He was very happy', '']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Mr. Smith bought ticket to San Francisco. He was very happy.\"\n",
    "text.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068335a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d8265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "921a00e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26d63090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr. Smith bought ticket to San Francisco.', 'He was very happy.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6231389a",
   "metadata": {},
   "source": [
    "## По пробелам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "699c64be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr.', 'Smith', 'bought', 'ticket', 'to', 'San', 'Francisco.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sentence = nltk.sent_tokenize(text)[0]\n",
    "en_sentence.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aca5d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Мистер', 'Смит', 'купил', 'билет', 'до', 'Сан-Франциско.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_sentence = \"Мистер Смит купил билет до Сан-Франциско.\"\n",
    "ru_sentence.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c6936c",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85699852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr.', 'Smith', 'bought', 'ticket', 'to', 'San', 'Francisco', '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(en_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efdf1e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Мистер', 'Смит', 'купил', 'билет', 'до', 'Сан-Франциско', '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(ru_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fce7531",
   "metadata": {},
   "source": [
    "## pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ac2eef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "мистер\n",
      "смит\n",
      "купить\n",
      "билет\n",
      "до\n",
      "сан-франциско\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "import pymorphy2\n",
    "m = pymorphy2.MorphAnalyzer()\n",
    "for t in nltk.word_tokenize(ru_sentence):\n",
    "    print(m.parse(t)[0].normal_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72c1e387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. NNP\n",
      "Smith NNP\n",
      "bought VBD\n",
      "ticket NN\n",
      "to TO\n",
      "San NNP\n",
      "Francisco NNP\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "for t, p in nltk.pos_tag(nltk.word_tokenize(en_sentence)):\n",
    "    print(t, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfeac6c1",
   "metadata": {},
   "source": [
    "## Вопрос на подумать\n",
    "А что делать с языками без пробелов?\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e1cd33",
   "metadata": {},
   "source": [
    "# BPE / Subword segmentation\n",
    "\n",
    "subword-nmt\n",
    "sentence-piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fab739",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install subword-nmt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7be101e",
   "metadata": {},
   "source": [
    "Посмотрим по шагам на обучение BPE-токенизации:\n",
    "\n",
    "увеличивая количество операций (`-s`), получаем новые токены в _словаре_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28bdf25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]\r",
      "100%|###########################################| 5/5 [00:00<00:00, 7397.36it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!subword-nmt learn-bpe -s 5 < train.txt > bpe_result.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65db408c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n@@ e@@ w@@ er l@@ o@@ w@@ er\r\n"
     ]
    }
   ],
   "source": [
    "!echo \"newer lower\" | subword-nmt apply-bpe -c bpe_result.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0d76c3",
   "metadata": {},
   "source": [
    "# Toy language model\n",
    "Научимся быстро считать частоты токенов/n-грамм в корпусе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f1e7f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d681f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"\n",
    "Лингви́стика (от лат. lingua «язык»), языкозна́ние, языкове́дение — наука, изучающая языки.\n",
    "Это наука о естественном человеческом языке вообще и обо всех языках мира как его индивидуализированных представителях.\n",
    "В широком смысле слова лингвистика подразделяется на научную и практическую. Чаще всего под лингвистикой подразумевается именно научная лингвистика. Является частью семиотики как науки о знаках.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6706a6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus = nltk.word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bad3ec",
   "metadata": {},
   "source": [
    "Как получить биграммы и триграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0eafb948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Лингви́стика', '('),\n",
       " ('(', 'от'),\n",
       " ('от', 'лат'),\n",
       " ('лат', '.'),\n",
       " ('.', 'lingua'),\n",
       " ('lingua', '«'),\n",
       " ('«', 'язык'),\n",
       " ('язык', '»'),\n",
       " ('»', ')'),\n",
       " (')', ','),\n",
       " (',', 'языкозна́ние'),\n",
       " ('языкозна́ние', ','),\n",
       " (',', 'языкове́дение'),\n",
       " ('языкове́дение', '—'),\n",
       " ('—', 'наука'),\n",
       " ('наука', ','),\n",
       " (',', 'изучающая'),\n",
       " ('изучающая', 'языки'),\n",
       " ('языки', '.'),\n",
       " ('.', 'Это'),\n",
       " ('Это', 'наука'),\n",
       " ('наука', 'о'),\n",
       " ('о', 'естественном'),\n",
       " ('естественном', 'человеческом'),\n",
       " ('человеческом', 'языке'),\n",
       " ('языке', 'вообще'),\n",
       " ('вообще', 'и'),\n",
       " ('и', 'обо'),\n",
       " ('обо', 'всех'),\n",
       " ('всех', 'языках'),\n",
       " ('языках', 'мира'),\n",
       " ('мира', 'как'),\n",
       " ('как', 'его'),\n",
       " ('его', 'индивидуализированных'),\n",
       " ('индивидуализированных', 'представителях'),\n",
       " ('представителях', '.'),\n",
       " ('.', 'В'),\n",
       " ('В', 'широком'),\n",
       " ('широком', 'смысле'),\n",
       " ('смысле', 'слова'),\n",
       " ('слова', 'лингвистика'),\n",
       " ('лингвистика', 'подразделяется'),\n",
       " ('подразделяется', 'на'),\n",
       " ('на', 'научную'),\n",
       " ('научную', 'и'),\n",
       " ('и', 'практическую'),\n",
       " ('практическую', '.'),\n",
       " ('.', 'Чаще'),\n",
       " ('Чаще', 'всего'),\n",
       " ('всего', 'под'),\n",
       " ('под', 'лингвистикой'),\n",
       " ('лингвистикой', 'подразумевается'),\n",
       " ('подразумевается', 'именно'),\n",
       " ('именно', 'научная'),\n",
       " ('научная', 'лингвистика'),\n",
       " ('лингвистика', '.'),\n",
       " ('.', 'Является'),\n",
       " ('Является', 'частью'),\n",
       " ('частью', 'семиотики'),\n",
       " ('семиотики', 'как'),\n",
       " ('как', 'науки'),\n",
       " ('науки', 'о'),\n",
       " ('о', 'знаках'),\n",
       " ('знаках', '.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Приводим к списку, потому что nltk возвращает генератор\n",
    "list(nltk.bigrams(tokenized_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2947ebdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Лингви́стика', '(', 'от'),\n",
       " ('(', 'от', 'лат'),\n",
       " ('от', 'лат', '.'),\n",
       " ('лат', '.', 'lingua'),\n",
       " ('.', 'lingua', '«'),\n",
       " ('lingua', '«', 'язык'),\n",
       " ('«', 'язык', '»'),\n",
       " ('язык', '»', ')'),\n",
       " ('»', ')', ','),\n",
       " (')', ',', 'языкозна́ние'),\n",
       " (',', 'языкозна́ние', ','),\n",
       " ('языкозна́ние', ',', 'языкове́дение'),\n",
       " (',', 'языкове́дение', '—'),\n",
       " ('языкове́дение', '—', 'наука'),\n",
       " ('—', 'наука', ','),\n",
       " ('наука', ',', 'изучающая'),\n",
       " (',', 'изучающая', 'языки'),\n",
       " ('изучающая', 'языки', '.'),\n",
       " ('языки', '.', 'Это'),\n",
       " ('.', 'Это', 'наука'),\n",
       " ('Это', 'наука', 'о'),\n",
       " ('наука', 'о', 'естественном'),\n",
       " ('о', 'естественном', 'человеческом'),\n",
       " ('естественном', 'человеческом', 'языке'),\n",
       " ('человеческом', 'языке', 'вообще'),\n",
       " ('языке', 'вообще', 'и'),\n",
       " ('вообще', 'и', 'обо'),\n",
       " ('и', 'обо', 'всех'),\n",
       " ('обо', 'всех', 'языках'),\n",
       " ('всех', 'языках', 'мира'),\n",
       " ('языках', 'мира', 'как'),\n",
       " ('мира', 'как', 'его'),\n",
       " ('как', 'его', 'индивидуализированных'),\n",
       " ('его', 'индивидуализированных', 'представителях'),\n",
       " ('индивидуализированных', 'представителях', '.'),\n",
       " ('представителях', '.', 'В'),\n",
       " ('.', 'В', 'широком'),\n",
       " ('В', 'широком', 'смысле'),\n",
       " ('широком', 'смысле', 'слова'),\n",
       " ('смысле', 'слова', 'лингвистика'),\n",
       " ('слова', 'лингвистика', 'подразделяется'),\n",
       " ('лингвистика', 'подразделяется', 'на'),\n",
       " ('подразделяется', 'на', 'научную'),\n",
       " ('на', 'научную', 'и'),\n",
       " ('научную', 'и', 'практическую'),\n",
       " ('и', 'практическую', '.'),\n",
       " ('практическую', '.', 'Чаще'),\n",
       " ('.', 'Чаще', 'всего'),\n",
       " ('Чаще', 'всего', 'под'),\n",
       " ('всего', 'под', 'лингвистикой'),\n",
       " ('под', 'лингвистикой', 'подразумевается'),\n",
       " ('лингвистикой', 'подразумевается', 'именно'),\n",
       " ('подразумевается', 'именно', 'научная'),\n",
       " ('именно', 'научная', 'лингвистика'),\n",
       " ('научная', 'лингвистика', '.'),\n",
       " ('лингвистика', '.', 'Является'),\n",
       " ('.', 'Является', 'частью'),\n",
       " ('Является', 'частью', 'семиотики'),\n",
       " ('частью', 'семиотики', 'как'),\n",
       " ('семиотики', 'как', 'науки'),\n",
       " ('как', 'науки', 'о'),\n",
       " ('науки', 'о', 'знаках'),\n",
       " ('о', 'знаках', '.')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nltk.trigrams(tokenized_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fab283",
   "metadata": {},
   "source": [
    "Посчитать количество каждого элемента в списке - Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e2b2456",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams = Counter(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "772a7676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Лингви́стика': 1,\n",
       "         '(': 1,\n",
       "         'от': 1,\n",
       "         'лат': 1,\n",
       "         '.': 6,\n",
       "         'lingua': 1,\n",
       "         '«': 1,\n",
       "         'язык': 1,\n",
       "         '»': 1,\n",
       "         ')': 1,\n",
       "         ',': 3,\n",
       "         'языкозна́ние': 1,\n",
       "         'языкове́дение': 1,\n",
       "         '—': 1,\n",
       "         'наука': 2,\n",
       "         'изучающая': 1,\n",
       "         'языки': 1,\n",
       "         'Это': 1,\n",
       "         'о': 2,\n",
       "         'естественном': 1,\n",
       "         'человеческом': 1,\n",
       "         'языке': 1,\n",
       "         'вообще': 1,\n",
       "         'и': 2,\n",
       "         'обо': 1,\n",
       "         'всех': 1,\n",
       "         'языках': 1,\n",
       "         'мира': 1,\n",
       "         'как': 2,\n",
       "         'его': 1,\n",
       "         'индивидуализированных': 1,\n",
       "         'представителях': 1,\n",
       "         'В': 1,\n",
       "         'широком': 1,\n",
       "         'смысле': 1,\n",
       "         'слова': 1,\n",
       "         'лингвистика': 2,\n",
       "         'подразделяется': 1,\n",
       "         'на': 1,\n",
       "         'научную': 1,\n",
       "         'практическую': 1,\n",
       "         'Чаще': 1,\n",
       "         'всего': 1,\n",
       "         'под': 1,\n",
       "         'лингвистикой': 1,\n",
       "         'подразумевается': 1,\n",
       "         'именно': 1,\n",
       "         'научная': 1,\n",
       "         'Является': 1,\n",
       "         'частью': 1,\n",
       "         'семиотики': 1,\n",
       "         'науки': 1,\n",
       "         'знаках': 1})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aef8af",
   "metadata": {},
   "source": [
    "Выведем топ по частоте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48b54704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 6),\n",
       " (',', 3),\n",
       " ('наука', 2),\n",
       " ('о', 2),\n",
       " ('и', 2),\n",
       " ('как', 2),\n",
       " ('лингвистика', 2),\n",
       " ('Лингви́стика', 1),\n",
       " ('(', 1),\n",
       " ('от', 1)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigrams.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab3dee2",
   "metadata": {},
   "source": [
    "## Нормализуем частоты\n",
    "Чтобы получить вероятности униграмм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a7485c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(tokenized_corpus)\n",
    "for k in unigrams:\n",
    "    unigrams[k] /= n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e22fd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 0.09230769230769231),\n",
       " (',', 0.046153846153846156),\n",
       " ('наука', 0.03076923076923077),\n",
       " ('о', 0.03076923076923077),\n",
       " ('и', 0.03076923076923077),\n",
       " ('как', 0.03076923076923077),\n",
       " ('лингвистика', 0.03076923076923077),\n",
       " ('Лингви́стика', 0.015384615384615385),\n",
       " ('(', 0.015384615384615385),\n",
       " ('от', 0.015384615384615385)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigrams.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a35e36",
   "metadata": {},
   "source": [
    "Оценим вероятность тестового предложения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "462851ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = nltk.word_tokenize(\"Лингвистика - это наука о языке.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b859101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "p = 1.\n",
    "for token in test_sentence:\n",
    "    p *= unigrams[token]\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca327b2",
   "metadata": {},
   "source": [
    "!! Почему тут 0?\n",
    "\n",
    "Применим простейшее сглаживание:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a23f5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.895733233026051e-12\n"
     ]
    }
   ],
   "source": [
    "p = 1.\n",
    "for token in test_sentence:\n",
    "    if unigrams[token]:\n",
    "        p *= unigrams[token]\n",
    "    else:\n",
    "        p *= 1 / n  # заменяем частоту=0 на 1\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7837af7",
   "metadata": {},
   "source": [
    "Приведем вероятность к более удобочитаемому виду:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140f897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "log(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
