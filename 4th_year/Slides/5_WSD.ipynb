{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75d8244e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Word Sense Disambiguation (WSD)\n",
    "\n",
    "## Разрешение лексической неоднозначности\n",
    "## Е.В. Еникеева\n",
    "## 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc580e2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Постановка задачи\n",
    "\n",
    "**Разрешение лексической / семантической неоднозначности**\n",
    "\n",
    "Вопросы:\n",
    "- Sense vs. Meaning (смысл/значение)\n",
    "- Разграничение лексических значений\n",
    "\n",
    "-> обычно имеем определенный *sense inventory*:\n",
    "- набор значений из словаря\n",
    "- синсеты тезауруса\n",
    "- варианты перевода\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76fd676",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Постановка задачи\n",
    "\n",
    "(Примеры)\n",
    "\n",
    "| | |\n",
    "| :-: | :-: |\n",
    "| Мелко порубить белки, **лук**, каперсы, анчоусы и травы. | Бойницы для стрельбы из **лука** в ингушских храмах. |\n",
    "| После угощения **собачки** лают с каким-то новым, особым остервенением. | При английской раскладке не могу набрать **собачку** |\n",
    "| Дурноты как не бывало, я **запалил** спиртовку, выпил кофе, разжевал гущу и выполз наружу. | Ненавижу, когда учитель **запалил** плеер и требует положить его на учительский стол. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e16ba5d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Мотивация\n",
    "\n",
    "1. омонимия / многозначность в АОТ\n",
    "2. группировка лексики, автоматическое создание лексикографических ресурсов (словарей, тезаурусов)\n",
    "\n",
    "## Семантическая неоднозначность\n",
    "* омонимия\n",
    "* полисемия  \n",
    "  - Bank vs. bank\n",
    "  - естественный язык vs. Говяжий язык\n",
    "  - Он нашел возможность vs. Он нашел квартиру\n",
    "  - мусоровоз"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a08e200",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Применение в IR\n",
    "\n",
    "<img src=\"5_WSD/1.png\" width=800/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982dd635",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Применение в IR\n",
    "\n",
    "<img src=\"5_WSD/2.png\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103d0f86",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Применение в MT\n",
    "\n",
    "<img src=\"5_WSD/translate_1.png\" width=900/>\n",
    "<img src=\"5_WSD/translate_2.png\" width=900/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3434dd95",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Классификация текстов\n",
    "\n",
    "    ... и другие задачи обработки целого текста, связанные со значением\n",
    "\n",
    "<img src=\"5_WSD/class.png\" width=1000/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e1c88c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Кореферентные цепочки\n",
    "\n",
    "<img src=\"5_WSD/coref_1.png\"/>\n",
    "\n",
    "<br/>\n",
    "<img src=\"5_WSD/coref_2.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a01b20f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Варианты постановки задачи\n",
    "\n",
    "## Классическая WSD\n",
    "* N значений (знаем **число N**, есть словарь)\n",
    "* обучаемся автоматически относить словоформу в тексте к одному из значений\n",
    "\n",
    "## Word Sense Induction \n",
    "* изначально **не знаем ничего** о многозначности\n",
    "* пытаемся выделить разные смыслы слов \n",
    "* группируем похожие употребления слов:\n",
    "  * unsupervised\n",
    "  * расстояния между контекстами\n",
    "  * кластеризация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ea6ab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Подходы\n",
    "\n",
    "1. Knowledge-Based: словари, тезаурусы и т.п.\n",
    "2. Supervised Learning: размеченный по значениям корпус \n",
    "3. Semi-supervised: небольшой размеченный корпус, bootstrapping и т.п.\n",
    "4. Unsupervised Learning – WSI "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eae2fb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Итоговая постановка задачи\n",
    "\n",
    "__Объекты__: слово $w_i$ в контексте $c_k$\n",
    "<br/>( признаковое описание объекта )\n",
    "\n",
    "__Ответы__: \n",
    "* значение $s_j$ слова $w_i$ в контексте $c_k$\n",
    "* значения из лексикографического источника\n",
    "* таксономические классы в онтологии\n",
    "* значения, выделенные экспертом для конкретной задачи, извлекаются из размеченного вручную корпуса\n",
    "* заранее неизвестны"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61b4abe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Корпуса для WSD\n",
    "\n",
    "### Lexical sample task:\n",
    "(размеченные контексты для ограниченной выборки многозначных лексем)\n",
    "* Line-hard-serve корпус – каждый по 4000\n",
    "* Interest корпус - 2369 размеченных примеров\n",
    "\n",
    "### All words:\n",
    "(Каждое слово + тег-значение по словарю - *semantic concordance*)\n",
    "* SemCor: 234,000 слов из Brown Corpus по WordNet\n",
    "* SENSEVAL-3 – 2081 размеченных слов\n",
    "* Датасет для русского: RUSSE – слово в контексте\n",
    "* Значения в НКРЯ: http://sensefreq.ruslang.ru/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573ced00",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Интересная новая статья про датасет для оценки семантической близости:\n",
    "https://aclanthology.org/2021.acl-long.550.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8020f6ee",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## All-words WSD task\n",
    "\n",
    "<img src=\"5_WSD/allw.png\"/>\n",
    "\n",
    "(Иллюстрация из Jurafsky,Martin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81d45e1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Оценка\n",
    "\n",
    "- F1-score по сравнению с ручной разметкой\n",
    "\n",
    "### Baseline\n",
    "\n",
    "- самое частое значение из размеченного корпуса - довольно точный"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a6bef9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Knowledge-based WSD\n",
    "\n",
    "1. Метод контекстного пересечения <br/>\n",
    "Используем словарные определения\n",
    "2. Алгоритм Леска <br/>\n",
    "Используем словарные определения\n",
    "3. Графовые методы <br/>\n",
    "Расстояния в тезаурусах\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e5eee2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Метод контекстного пересечения\n",
    "\n",
    "Сравниваем слова контекста со словами из определений для каждого значения\n",
    "\n",
    "Контекст: *Благодаря **спорту** **стрельба** из лука получила новое название и развитие лука: потребовала изменить его форму, конструкцию и технологию изготовления.*\n",
    "\n",
    "> I ЛУК, (в знач. сорта) луки, - Огородное или дикорастущее растение сем. лилейных с острым вкусом луковицы и съедобными трубчатыми листьями. \n",
    "Репчатый л. Зелёный л. (листья). Головка лука. Дикие луки.\n",
    "\n",
    "> II. ЛУК, - Ручное оружие для метания стрел в виде пружинящей дуги, стянутой тетивой. Тугой л. Стрельба из лука (вид спорта).\n",
    "\n",
    "\n",
    "$F(s_1) = {огородное, растение, вкус, луковица, съедобный, лист, репчатый, зелёный, головка ...}$\n",
    "\n",
    "$F(s_2) = {оружие, метание, стрела, дуга, тетива, тугой, стрельба, спорт ...}$\n",
    "\n",
    "$|F(s_1)\\cap F(context)| = 0$\n",
    "\n",
    "$|F(s_2)\\cap F(context)| = 2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415e2b17",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Алгоритм Леска\n",
    "\n",
    "(Упрощенный алгоритм Леска - метод контекстного пересечения)\n",
    "\n",
    "\n",
    "\tE.g. “On burning coal we get ash.”\n",
    "\n",
    "|Ash|Coal|\n",
    "|:-|:-|\n",
    "|Trees of the olive family with pinnate leaves, thin furrowed bark and gray branches.|A piece of glowing carbon or **burnt** wood.|\n",
    "|The **solid** residue left when **combustible** material is thoroughly **burned** or oxidized.|Charcoal.|\n",
    "|To convert into ash.|A black **solid combustible** substance formed by the partial decomposition of vegetable matter without free access to air and under the influence of moisture and often increased pressure and temperature that is widely used as a fuel for **burning**.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4eb785",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Lesk, M. (1986). Automatic sense disambiguation using machine readable dictionaries: how to tell a pine cone from an ice cream cone. In Proceedings of the 5th annual international conference on Systems documentation (pp. 24-26)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ae05f5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Как улучшить оценку пересечения\n",
    "\n",
    "- Удалить стоп-слова\n",
    "- Учитывать синонимию (WordNet)\n",
    "- Взвешивание по IDF\n",
    "- Сравнивать tf*idf векторы контекста и определения\n",
    "- Сравнивать эмбеддинги слов контекста и определения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0e5efe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Графовые методы\n",
    "## Алгоритм Вокера (Walker's)\n",
    "\n",
    "1. Для каждого значения ключевого слова найти соответствующий тезаурусный класс\n",
    "2. Вычислить вес каждого из значений на основе контекстных слов. К значению прибавляется 1, если контекстное слово принадлежит тому же тезаурусному классу\n",
    "\n",
    "E.g. The money in this **bank** fetches an interest of 8% per annum\n",
    "\n",
    "Target word: **bank**\n",
    "\n",
    "Clue words from the context: money, interest, annum, fetch\n",
    "\n",
    "## Другие\n",
    "- Использование мер relatedness\n",
    "- PageRank для обхода подграфа с ключевым словом и контекстными словами\n",
    "- Концептуальная плотность (conceptual density)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8316384",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Supervised методы\n",
    "\n",
    "Главная задача – построить признаковое представление значений / контекстов\n",
    "* Мешок слов\n",
    "* Коллокационные фичи\n",
    "\\- токены в определённой позиции (например, Nobj для глаголов)\n",
    "* POS-теги\n",
    "* ... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec0b415",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Embeddings\n",
    "\n",
    "# AdaGram\n",
    "\n",
    "* Идея: будем учить несколько эмбеддингов для каждого слова\n",
    "* Adaptive Skip-gram: дополнительная переменная – множество всех значений всех слов корпуса\n",
    "* Можем оценить вероятность каждого значения $z_i$ слова $x$ в контексте $y$\n",
    "\n",
    "\n",
    "Demo: http://adagram.ll-cl.org/about \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339645ad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ELMo\n",
    "\n",
    "<font size=\"4\">[ELMo](https://arxiv.org/pdf/1802.05365.pdf) — модель, которая позволяет получить не просто вектор слова W,\n",
    "а _вектор слова W в контексте C_ - **контекстуальный эмбеддинг**.<br/>\n",
    "Обучаем двунаправленную (bidirectional) языковую модель примерно так*:</font>\n",
    "\n",
    "<img src=\"https://jalammar.github.io/images/Bert-language-modeling.png\" alt=\"elmo\" width=300/>\n",
    "\n",
    "<font size=\"4\">Но затем мы не просто берем какие-то представления отдельных слов, а сохраняем все веса и пропускаем каждое \n",
    "предложение для новой задачи через такую сетку с этими весами. Получаем вектора для всех слов в предложении из нескольких слоев!</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2f5f33",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "\\* картинка из [блога](https://jalammar.github.io/) Jay Allamar - кстати, очень доступные объяснения всяких NLP-штук с картинками"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c16d7e",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Вспомнить, что такое языковая модель:\n",
    "[слайды прошлого года](https://drive.google.com/file/d/1qpyqYzVM9xtgkC1rbHAaBPTGfnwDo4Rm/view?usp=sharing)\n",
    "\n",
    "Эта же идея лежит в основе других больших предобученных моделей - BERT, GPT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2a9a3f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Контекстуальные эмбеддинги в задаче WSD\n",
    "\n",
    "### Supervised классификатор\n",
    "\\- для каждого значения можно посчитать средний вектор (центроид) этого значения\n",
    "\n",
    "<img src=\"5_WSD/nn.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3768399e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Для слов, которых не было в обучающем корпусе\n",
    "\\- можно «распространить» центроиды по WordNet\n",
    "* для каждого значения $\\hat{s} \\in W$:\n",
    "  * вектора других слов синсета $S_{\\hat{s}}$,\n",
    "  * вектора гиперонимов $H_{\\hat{s}}$, \n",
    "  * вектор(а) категории $L_{\\hat{s}}$\n",
    "  \n",
    "тогда вектор значения вычисляется так:\n",
    "\n",
    "$$if |S_{\\hat{s}}|>0, v_{\\hat{s}}=\\frac{1}{|S_{\\hat{s}}|}\\sum{v_{syn}}, \\forall v_{syn} \\in S_{\\hat{s}}$$\n",
    "$$else if |H_{\\hat{s}}|>0, v_{\\hat{s}}=\\frac{1}{|H_{\\hat{s}}|}\\sum{v_{syn}}, \\forall v_{syn} \\in H_{\\hat{s}}$$\n",
    "$$else if |L_{\\hat{s}}|>0, v_{\\hat{s}}=\\frac{1}{|L_{\\hat{s}}|}\\sum{v_{syn}}, \\forall v_{syn} \\in L_{\\hat{s}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24bd025",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### WSI + contextualized embeddings\n",
    "\n",
    "- Для каждого слова $𝑤$\n",
    "  - Для каждого вхождения $𝑤_𝑖$ в контексте $c$\n",
    "    - можем вычислить контекстный вектор\n",
    "  - Кластеризуем контексты\n",
    "    - Agglomerative clustering\n",
    "    - k-means\n",
    "    - DBSCAN\n",
    "    - …\n",
    "  - Вычисляем центроид каждого кластера \n",
    "    > вектор значения\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f07ba05",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Глава в учебнике Jurasky+Martin: [Word Senses and WordNet](https://web.stanford.edu/~jurafsky/slp3/18.pdf)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
